{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Pipeline\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables / settings for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject-independant directory and filename of raw-data\n",
    "input_subject_file = f\"..\\\\data\\\\preprocessed\\\\subject-{subject_no}.tsv\"\n",
    "# path to stimuli of experiment\n",
    "exp_stimuli_folder = \"..\\\\stimuli\\\\\"\n",
    "# set global colormap var\n",
    "cmp = plt.cm.viridis_r\n",
    "# display resolution\n",
    "display = {\"width\": 1920, \"height\": 1080}\n",
    "# read data\n",
    "data = pd.read_csv(input_subject_file, sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create asset directory for subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder name\n",
    "plt_folder_name = f'..\\\\plots\\\\subject-{subject_no}'\n",
    "\n",
    "# Check if the folder exists, if not, create it\n",
    "if not os.path.exists(plt_folder_name):\n",
    "    os.makedirs(plt_folder_name)\n",
    "    print(f\"Folder {plt_folder_name} created.\")\n",
    "else:\n",
    "    print(f\"Folder {plt_folder_name} already exists. Skipping...\")\n",
    "\n",
    "plots_folder_name = os.path.abspath(plt_folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis\n",
    "\n",
    "### 4.0. Investigating gaze positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# areas of interest\n",
    "def gazepos(data, sentence_id):\n",
    "\n",
    "    # get samples with specific id\n",
    "    data_subset = data.query(f\"SENTENCE_ID=={sentence_id}\")\n",
    "    data_subset = data_subset.query(f\"EVENT=='PREVIEW' or EVENT=='AUDIOSTART' or EVENT=='VERBONSET' or EVENT=='TARGETONSET' or EVENT=='PAUSE'\")\n",
    "\n",
    "    # filter invalid samples\n",
    "    data_subset = data_subset.query(\"BPOGX>=0 and BPOGY >=0\")\n",
    "    \n",
    "    # sort by time\n",
    "    data_subset = data_subset.sort_values(by=\"TIME\", ascending=True)\n",
    "\n",
    "    # reset index\n",
    "    data_subset = data_subset.reset_index(drop=True)\n",
    "\n",
    "    # get cuest    \n",
    "    preview = data_subset.query(\"EVENT=='PREVIEW'\").sort_values(by=\"TIME\", ascending=True).reset_index(drop=True).loc[0, \"TIME\"]\n",
    "    audiostart = data_subset.query(\"EVENT=='AUDIOSTART'\").sort_values(by=\"TIME\", ascending=True).reset_index(drop=True).loc[0, \"TIME\"]\n",
    "    verb_onset = data_subset.query(\"EVENT=='VERBONSET'\").sort_values(by=\"TIME\", ascending=True).reset_index(drop=True).loc[0, \"TIME\"]\n",
    "    target_onset = data_subset.query(\"EVENT=='TARGETONSET'\").sort_values(by=\"TIME\", ascending=True).reset_index(drop=True).loc[0, \"TIME\"]\n",
    "    pause = data_subset.query(\"EVENT=='PAUSE'\").sort_values(by=\"TIME\", ascending=True).reset_index(drop=True).loc[0, \"TIME\"]\n",
    "\n",
    "    # define sentence for title\n",
    "    stc = data_subset.loc[0, \"SENTENCE\"]\n",
    "    condition = data_subset.loc[0, \"CONDITION\"]\n",
    "\n",
    "    # plot \n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    \n",
    "    plt.scatter(data_subset[\"TIME\"],data_subset[\"BPOGX\"],s=2,color=\"blue\",label=\"BPOGX\")\n",
    "    plt.scatter(data_subset[\"TIME\"],data_subset[\"BPOGY\"]-1,s=2,color=\"orange\",label=\"BPOGY\")\n",
    "\n",
    "    # labels and ticks\n",
    "    plt.axvline(x = preview, color = 'k', label = 'Preview/Pause')\n",
    "    plt.axvline(x = audiostart, color = 'r', label = 'AUDIOSTART')\n",
    "    plt.axvline(x = verb_onset, color = 'g', label = 'VERBONSET')\n",
    "    plt.axvline(x = target_onset, color = 'm', label = 'TARGETONSET')\n",
    "    plt.axvline(x = pause, color = 'k')\n",
    "\n",
    "    plt.title(\"Gazepositions of participant \" + str(subject_no) + \" for sentence (ID: \" + str(sentence_id) + \", Condition: \" + condition + \"):  \" + stc)\n",
    "    plt.xlabel(\"Time in s\")\n",
    "    plt.ylabel(\"X- and Y-Point of gaze as a fraction of the screen size\")\n",
    "    plt.xlim((preview-.3, pause+1))\n",
    "    plt.legend(loc=\"center right\", framealpha=1)\n",
    "\n",
    "    # save plot to assets\n",
    "    fig.savefig(f'{plots_folder_name}/3-sanity-gazepos_{str(sentence_id)}_{condition.lower()}.png')\n",
    "\n",
    "gazepos(data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Scanpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scanpath(data, sentence_id):\n",
    "\n",
    "    # get samples with specific id\n",
    "    data_subset = data.query(f\"SENTENCE_ID=={sentence_id}\")\n",
    "    data_subset = data_subset.query(f\"EVENT=='AUDIOSTART' or EVENT=='VERBONSET' or EVENT=='TARGETONSET'\")\n",
    "\n",
    "    # filter invalid samples\n",
    "    data_subset = data_subset.query(\"BPOGX>=0 and BPOGY >=0\")\n",
    "    \n",
    "    # reset index\n",
    "    data_subset = data_subset.reset_index(drop=True)\n",
    "\n",
    "    # get first row of dataframe\n",
    "    first_row = data_subset.iloc[0]\n",
    "\n",
    "    # get position to monitor size\n",
    "    for index, value in data_subset['BPOGX'].items():\n",
    "        data_subset.at[index, 'BPOGX'] = value * display['width']\n",
    "    for index, value in data_subset['BPOGY'].items():\n",
    "        data_subset.at[index, 'BPOGY'] = value * display['height']\n",
    "\n",
    "    # sentence information\n",
    "    stc = first_row[\"SENTENCE\"]\n",
    "    condition = data_subset.loc[0, \"CONDITION\"]\n",
    "\n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    plt.title(\"Scanpath participant \" + str(subject_no) + \" for sentence (ID: \" + str(sentence_id) + \", Condition: \" + condition + \"):  \" + stc)\n",
    "    \n",
    "    # background image\n",
    "    im = plt.imread(exp_stimuli_folder + str(sentence_id) + \"-\" + condition + \".png\")\n",
    "    plt.imshow(im, alpha=.8)\n",
    "    \n",
    "    norm_time = (data_subset['TIME'] - data_subset['TIME'].min()) / (data_subset['TIME'].max() - data_subset['TIME'].min())\n",
    "    dat_sub_len = len(data_subset) - 1\n",
    "\n",
    "    for i in range(dat_sub_len):\n",
    "        \n",
    "        plt.plot(\n",
    "            data_subset.iloc[i:i+2]['BPOGX'], \n",
    "            data_subset.iloc[i:i+2]['BPOGY'], \n",
    "            c=cmp(norm_time.iloc[i]),\n",
    "            linewidth=3,\n",
    "            label='start scanpath' if i == 0  else 'end scanpath' if i == dat_sub_len-1 else \"\"\n",
    "        )\n",
    "    \n",
    "    # scanpath start marker\n",
    "    plt.text(data_subset.iloc[0]['BPOGX'], data_subset.iloc[0]['BPOGY'], 'start', fontweight='bold')\n",
    "    plt.plot(data_subset.iloc[0]['BPOGX'], data_subset.iloc[0]['BPOGY'], color=cmp(norm_time.iloc[0]), marker='o', markeredgecolor='black', linewidth=100)\n",
    "    # scanpath stop marker\n",
    "    plt.text(data_subset.iloc[dat_sub_len]['BPOGX'], data_subset.iloc[dat_sub_len]['BPOGY'], 'stop', fontweight='bold')\n",
    "    plt.plot(data_subset.iloc[dat_sub_len]['BPOGX'], data_subset.iloc[dat_sub_len]['BPOGY'], color=cmp(norm_time.iloc[dat_sub_len]), marker='o', markeredgecolor='black', linewidth=100)\n",
    "    \n",
    "    # labels and ticks\n",
    "    plt.xlabel(\"BPOGX\")\n",
    "    plt.ylabel(\"BPOGY\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # display scanpath\n",
    "    plt.show()\n",
    "\n",
    "    # save plot to assets\n",
    "    fig.savefig(f'{plots_folder_name}/4-analysis-scanpath_{str(sentence_id)}_{condition.lower()}.png')\n",
    "\n",
    "\n",
    "show_scanpath(data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "def show_heatmap(data, sentence_id):\n",
    "\n",
    "    # get samples with specific id\n",
    "    data_subset = data.query(f\"SENTENCE_ID=={sentence_id}\")\n",
    "    data_subset = data_subset.query(f\"EVENT=='AUDIOSTART' or EVENT=='VERBONSET' or EVENT=='TARGETONSET'\")\n",
    "\n",
    "    # filter invalid samples\n",
    "    data_subset = data_subset.query(\"BPOGX>=0 and BPOGY >=0\")\n",
    "    \n",
    "    # reset index\n",
    "    data_subset = data_subset.reset_index(drop=True)\n",
    "\n",
    "    # get first row of dataframe\n",
    "    first_row = data_subset.iloc[0]\n",
    "\n",
    "    for index, value in data_subset['BPOGX'].items():\n",
    "        data_subset.at[index, 'BPOGX'] = value * display['width']\n",
    "    for index, value in data_subset['BPOGY'].items():\n",
    "        data_subset.at[index, 'BPOGY'] = value * display['height']\n",
    "\n",
    "    stc = first_row[\"SENTENCE\"]\n",
    "    condition = data_subset.loc[0, \"CONDITION\"]\n",
    "    \n",
    "\n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    \n",
    "    sns.kdeplot(data=data_subset, x='BPOGX', y='BPOGY', fill=True, cmap=\"viridis\", thresh=0, levels=100, alpha=0.5)\n",
    "    \n",
    "    # background image\n",
    "    im = plt.imread(exp_stimuli_folder + str(sentence_id) + \"-\" + condition + \".png\")\n",
    "    plt.imshow(im)\n",
    "\n",
    "    # labels and ticks\n",
    "    plt.title(\"Heatmap participant \" + str(subject_no) + \" for sentence (ID: \" + str(sentence_id) + \", Condition: \" + condition + \"):  \" + stc)\n",
    "    plt.xlabel(\"BPOGX\")\n",
    "    # plt.xlim((0, display[\"width\"]))\n",
    "    # plt.ylim((display[\"height\"], 0))\n",
    "    plt.ylabel(\"BPOGY\")\n",
    "    \n",
    "    # display plot\n",
    "    plt.show()\n",
    "\n",
    "    # save plot to assets\n",
    "    fig.savefig(f'{plots_folder_name}/4-analysis-heatmap_{str(sentence_id)}_{condition.lower()}.png')\n",
    "\n",
    "show_heatmap(data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Metrics\n",
    "### 4.3.0 Area of interest helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpog_in_target_bbox(bpogx, bpogy, pos):\n",
    "\n",
    "    width = display[\"width\"]\n",
    "    height = display[\"height\"]\n",
    "\n",
    "    x = bpogx * width\n",
    "    y = bpogy * height\n",
    "    \n",
    "    if pos == \"TL\":\n",
    "        relpos = (width/4, height/4)\n",
    "    elif pos == \"TR\":\n",
    "        relpos = (width*(3/4), height/4)\n",
    "    elif pos == \"BL\":\n",
    "        relpos = (width/4, height*(3/4))\n",
    "    elif pos == \"BR\":\n",
    "        relpos = (width*(3/4), height*(3/4))\n",
    "    else:\n",
    "        relpos = -1\n",
    "\n",
    "    pos_x_l = relpos[0] - 200\n",
    "    pos_x_r = relpos[0] + 200\n",
    "    pos_y_d = relpos[1] - 200\n",
    "    pos_y_u = relpos[1] + 200\n",
    "\n",
    "    if (x > pos_x_l) and (x < pos_x_r):\n",
    "        if(y > pos_y_d) and (y < pos_y_u):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_bounding_box_coords(pos):\n",
    "    \n",
    "    relpos = 0    \n",
    "    width = display[\"width\"]\n",
    "    height = display[\"height\"]\n",
    "\n",
    "\n",
    "    if pos == \"TL\":\n",
    "        relpos = (width/4, height/4)\n",
    "    elif pos == \"TR\":\n",
    "        relpos = (width*(3/4), height/4)\n",
    "    elif pos == \"BL\":\n",
    "        relpos = (width/4, height*(3/4))\n",
    "    elif pos == \"BR\":\n",
    "        relpos = (width*(3/4), height*(3/4))\n",
    "    else:\n",
    "        relpos = -1\n",
    "\n",
    "    pos_x_l = relpos[0] - 200\n",
    "    pos_x_r = relpos[0] + 200\n",
    "    pos_y_d = relpos[1] - 200\n",
    "    pos_y_u = relpos[1] + 200\n",
    "    \n",
    "    return (pos_x_l, pos_x_r, pos_y_d, pos_y_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Areas of interest algorithm verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_aoi(data, sentence_id):\n",
    "\n",
    "    # set dict vor visualisation of position\n",
    "    pos_dict = {\"TL\": \"top left\", \"TR\" : \"top right\", \"BL\" : \"bottom left\", \"BR\" : \"bottom right\"}\n",
    "\n",
    "    # get samples with specific id\n",
    "    data_subset = data.query(f\"SENTENCE_ID=={sentence_id}\")\n",
    "    data_subset = data_subset.query(f\"EVENT=='AUDIOSTART' or EVENT=='VERBONSET' or EVENT=='TARGETONSET'\")\n",
    "\n",
    "    # filter invalid samples\n",
    "    data_subset = data_subset.query(\"BPOGV==1 and BPOGX>=0 and BPOGY >=0\")\n",
    "    \n",
    "    # reset index\n",
    "    data_subset = data_subset.reset_index(drop=True)\n",
    "\n",
    "    # get first row of dataframe\n",
    "    first_row = data_subset.iloc[0]\n",
    "\n",
    "    stc = first_row[\"SENTENCE\"]\n",
    "    condition = data_subset.loc[0, \"CONDITION\"]\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(2,2,figsize=(16,9))\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    \n",
    "    # show background image\n",
    "    for a in ax.flatten():\n",
    "        im = plt.imread(exp_stimuli_folder + str(sentence_id) + \"-\" + condition + \".png\")\n",
    "        a.imshow(im, alpha=.3)\n",
    "    \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 2): \n",
    "            \n",
    "            for index, value in data_subset['BPOGX'].items():\n",
    "\n",
    "                x_rel = data_subset.at[index, 'BPOGX']\n",
    "                y_rel = data_subset.at[index, 'BPOGY']\n",
    "                \n",
    "                pos = \"\"\n",
    "                if i == 0 and j == 0:\n",
    "                    pos = \"TL\"\n",
    "                elif i == 0 and j == 1:\n",
    "                    pos = \"TR\"\n",
    "                elif i == 1 and j == 0:\n",
    "                    pos = \"BL\"\n",
    "                elif i == 1 and j == 1:\n",
    "                    pos = \"BR\"\n",
    "\n",
    "                # print lines of bounding box\n",
    "                tldat = get_bounding_box_coords(pos)\n",
    "                ax[i, j].axvline(x = tldat[0], color = 'grey', linewidth=.5)\n",
    "                ax[i, j].axvline(x = tldat[1], color = 'grey', linewidth=.5)\n",
    "                ax[i, j].axhline(y = tldat[2], color = 'grey', linewidth=.5)\n",
    "                ax[i, j].axhline(y = tldat[3], color = 'grey', linewidth=.5)\n",
    "\n",
    "                # plot sample\n",
    "                ax[i, j].plot(x_rel*display[\"width\"], y_rel*display[\"height\"], marker='o', markeredgecolor='black', linewidth=10, color='green' if bpog_in_target_bbox(x_rel, y_rel, pos)  else 'red')\n",
    "                \n",
    "\n",
    "                # set labels\n",
    "                ax[i, j].set_title(f\"Target position {pos} ({pos_dict[pos]})\")\n",
    "                \n",
    "                if (i == 1):\n",
    "                    ax[i, j].set_xlabel('BPOGX')\n",
    "                if (j == 0):\n",
    "                    ax[i, j].set_ylabel('BPOGY')\n",
    "\n",
    "    # titles\n",
    "    fig.suptitle(\"Verification of area of interest detection algorithem for subject \" + str(subject_no) + \" and sentence (ID: \" + str(sentence_id) + \", Condition: \" + condition + \"):  \" + stc)\n",
    "\n",
    "    # display plot\n",
    "    plt.show()\n",
    "    \n",
    "    # save plot to assets\n",
    "    fig.savefig(f'{plots_folder_name}/4-analysis-aoi_alg_{str(sentence_id)}_{condition.lower()}.png')\n",
    "\n",
    "\n",
    "calc_aoi(data, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Target Ratio and Non-Target Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tr_ntr(data, highlight, show_measure_pt, sentence_id):\n",
    "\n",
    "    # get samples with specific id\n",
    "    data_subset = data.query(f\"SENTENCE_ID=={sentence_id}\")\n",
    "    data_subset = data_subset.query(f\"EVENT=='AUDIOSTART' or EVENT=='VERBONSET' or EVENT=='TARGETONSET'\")\n",
    "    \n",
    "    # filter invalid samples\n",
    "    data_subset = data_subset.query(\"BPOGX>=0 and BPOGY >=0\")\n",
    "    \n",
    "    # reset index\n",
    "    data_subset = data_subset.reset_index(drop=True)\n",
    "\n",
    "    # get cues\n",
    "    audiostart = data_subset.query(\"EVENT=='AUDIOSTART'\").sort_values(by=\"TIME\", ascending=True).reset_index(drop=True).loc[0, \"TIME\"]\n",
    "    verb_onset = data_subset.query(\"EVENT=='VERBONSET'\").sort_values(by=\"TIME\", ascending=True).reset_index(drop=True).loc[0, \"TIME\"]\n",
    "    target_onset = data_subset.query(\"EVENT=='TARGETONSET'\").sort_values(by=\"TIME\", ascending=True).reset_index(drop=True).loc[0, \"TIME\"]\n",
    "\n",
    "    # get first row of dataframe\n",
    "    first_row = data_subset.iloc[0]\n",
    "\n",
    "    stc = first_row[\"SENTENCE\"]\n",
    "    condition = data_subset.loc[0, \"CONDITION\"]\n",
    "    t_pos = first_row[\"TARGET_POS\"]\n",
    "    print(t_pos)\n",
    "    # determin other AOIs\n",
    "    all_t_pos = [\"TL\", \"TR\", \"BL\", \"BR\"]\n",
    "    all_t_pos.remove(t_pos)\n",
    "\n",
    "\n",
    "    for index, row in data_subset.iterrows():\n",
    "        \n",
    "        idx = index + 1\n",
    "\n",
    "        x = row[\"BPOGX\"]\n",
    "        y = row[\"BPOGY\"]\n",
    "        in_b_box = bpog_in_target_bbox(x, y, t_pos)\n",
    "        in_b_box_other = bpog_in_target_bbox(x, y, all_t_pos[0]) or bpog_in_target_bbox(x, y,  all_t_pos[1]) or bpog_in_target_bbox(x, y,  all_t_pos[2])\n",
    "        \n",
    "        # if first index\n",
    "        if in_b_box:\n",
    "            data_subset.at[index, \"TR\"] = 1\n",
    "            data_subset.at[index, \"NTR\"] = 0\n",
    "        else:\n",
    "            data_subset.at[index, \"TR\"] = 0 \n",
    "            if in_b_box_other:\n",
    "                data_subset.at[index, \"NTR\"] = 1\n",
    "            else:\n",
    "                data_subset.at[index, \"NTR\"] = 0\n",
    "\n",
    "    \n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(15,3))\n",
    "    \n",
    "    # labels and ticks    \n",
    "    plt.axvline(x = audiostart, linestyle='--', color = 'grey' if 'a' in highlight else 'k')\n",
    "    plt.text(audiostart-0.02, 1.06, 'AUDIOSTART', color = 'grey' if 'a' in highlight else 'k')\n",
    "    plt.axvline(x = verb_onset, linestyle='--', color = 'grey' if 'v' in highlight else 'k')\n",
    "    plt.text(verb_onset-0.02, 1.06, 'VERBONSET', color = 'grey' if 'v' in highlight else 'k')\n",
    "    plt.axvline(x = target_onset, linestyle='--', color = 'grey' if 't' in highlight else 'k')\n",
    "    plt.text(target_onset-0.02, 1.06, 'TARGETONSET', color = 'grey' if 't' in highlight else 'k')\n",
    "    if show_measure_pt:\n",
    "        plt.axvline(x=target_onset-50/1000, label = 'measure point', color = 'red')\n",
    "        \n",
    "    # data\n",
    "    plt.plot(data_subset[\"TIME\"],data_subset[\"NTR\"], color=\"#b8c1f2\",label=\"$ntr_{\"+condition.lower()+\"}$\")\n",
    "    plt.plot(data_subset[\"TIME\"],data_subset[\"TR\"], color=\"darkblue\",label=\"$tr_{\"+condition.lower()+\"}$\")\n",
    "\n",
    "    # more labels and ticks\n",
    "    plt.title(f\"Metrics of interest for subject {subject_no} and sentence (ID: {str(sentence_id)}): {stc}\\n\")\n",
    "    plt.xlim((audiostart-0.05, target_onset+.5))\n",
    "    plt.ylim((-0.05,1.05))\n",
    "    plt.ylabel(\"Metrics\")\n",
    "    plt.xlabel(\"Time in seconds\")\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # display plot\n",
    "    plt.show()\n",
    "\n",
    "    # save plot to assets\n",
    "    fig.savefig(f'{plots_folder_name}/4-analysis-metrics_{str(sentence_id)}_{condition.lower()}.png')\n",
    "\n",
    "def calc_tr_ntr_zoomed(data, highlight, show_measure_pt, sentence_id):\n",
    "\n",
    "    # get samples with specific id\n",
    "    data_subset = data.query(f\"SENTENCE_ID=={sentence_id}\")\n",
    "    data_subset = data_subset.query(f\"EVENT=='VERBONSET' or EVENT=='TARGETONSET'\")\n",
    "    \n",
    "    # filter invalid samples\n",
    "    data_subset = data_subset.query(\"BPOGV==1 and BPOGX>=0 and BPOGY >=0\")\n",
    "    \n",
    "    # reset index\n",
    "    data_subset = data_subset.reset_index(drop=True)\n",
    "\n",
    "    # get cues\n",
    "    verb_onset = data_subset.query(\"EVENT=='VERBONSET'\").sort_values(by=\"TIME\", ascending=True).reset_index(drop=True).loc[0, \"TIME\"]\n",
    "    target_onset = data_subset.query(\"EVENT=='TARGETONSET'\").sort_values(by=\"TIME\", ascending=True).reset_index(drop=True).loc[0, \"TIME\"]\n",
    "    \n",
    "    # get first row of dataframe\n",
    "    first_row = data_subset.iloc[0]\n",
    "\n",
    "    stc = first_row[\"SENTENCE\"]\n",
    "    condition = data_subset.loc[0, \"CONDITION\"]\n",
    "    t_pos = first_row[\"TARGET_POS\"]\n",
    "\n",
    "    # determin other AOIs\n",
    "    all_t_pos = [\"TL\", \"TR\", \"BL\", \"BR\"]\n",
    "    all_t_pos.remove(t_pos)\n",
    "\n",
    "    for index, row in data_subset.iterrows():\n",
    "\n",
    "        x = row[\"BPOGX\"]\n",
    "        y = row[\"BPOGY\"]\n",
    "        in_b_box = bpog_in_target_bbox(x, y, t_pos)\n",
    "        in_b_box_other = bpog_in_target_bbox(x, y, all_t_pos[0]) or bpog_in_target_bbox(x, y,  all_t_pos[1]) or bpog_in_target_bbox(x, y,  all_t_pos[2])\n",
    "\n",
    "        # if first index\n",
    "        if in_b_box:\n",
    "            data_subset.at[index, \"TR\"] = 1\n",
    "            data_subset.at[index, \"NTR\"] = 0\n",
    "        else:\n",
    "            data_subset.at[index, \"TR\"] = 0 \n",
    "            if in_b_box_other:\n",
    "                data_subset.at[index, \"NTR\"] = 1\n",
    "            else:\n",
    "                data_subset.at[index, \"NTR\"] = 0\n",
    "\n",
    "\n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    # labels and ticks\n",
    "    plt.axvline(x = verb_onset, linestyle='--', color = 'grey' if 'v' in highlight else 'k')\n",
    "    plt.text(verb_onset-0.02, 1.06, 'VERBONSET', color = 'grey' if 'v' in highlight else 'k')\n",
    "    plt.axvline(x = target_onset, linestyle='--', color = 'grey' if 't' in highlight else 'k')\n",
    "    plt.text(target_onset-0.02, 1.06, 'TARGETONSET', color = 'grey' if 't' in highlight else 'k')\n",
    "    if show_measure_pt:\n",
    "        plt.axvline(x=target_onset-50/1000, label = 'measure point', color = 'red')\n",
    "    \n",
    "    # data\n",
    "    plt.plot(data_subset[\"TIME\"],data_subset[\"NTR\"], color=\"#b8c1f2\",label=\"$ntr_{\"+condition.lower()+\"}$\")\n",
    "    plt.plot(data_subset[\"TIME\"],data_subset[\"TR\"], color=\"darkblue\",label=\"$tr_{\"+condition.lower()+\"}$\")\n",
    "\n",
    "    # more labels and ticks\n",
    "    plt.xlim((verb_onset-.2, target_onset+.2))\n",
    "    plt.ylim((-0.05,1.05))\n",
    "    plt.ylabel(\"Metrics\")\n",
    "    plt.xlabel(\"Time in seconds\")\n",
    "    plt.title(f\"Zoomed metrics of interest for subject {subject_no} and sentence (ID: {str(sentence_id)}): {stc}\\n\")\n",
    "\n",
    "    plt.legend(loc='center left')\n",
    "\n",
    "    # display plot\n",
    "    plt.show()\n",
    "\n",
    "    # save plot to assets\n",
    "    fig.savefig(f'{plots_folder_name}/4-analysis-zoomed_metrics_{str(sentence_id)}_{condition.lower()}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_tr_ntr(data, \"\", True, 1)\n",
    "calc_tr_ntr_zoomed(data, \"\", True, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Acquisition-and-Analysis-of-Eye-Tracking-D-mBfMmic6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
